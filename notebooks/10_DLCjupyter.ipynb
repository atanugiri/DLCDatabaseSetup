{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLabCut Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import python libraries needed for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart Kernel before running this cell if you've run other matplotlib commands\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atanugiri/miniconda3/envs/DEEPLABCUT/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DeepLabCut version: 3.0.0rc9\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import deeplabcut\n",
    "    import tkinter\n",
    "    from tkinter import filedialog\n",
    "    \n",
    "    print(f'Using DeepLabCut version: {deeplabcut. __version__}')\n",
    "\n",
    "except:\n",
    "    print(\"Please run the notebook in in your local environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You might have to import torch to use PyTorch engine ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1\n",
      "CUDA Available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"cuDNN Version:\", torch.backends.cudnn.version())\n",
    "    print(\"cuDNN Enabled:\", torch.backends.cudnn.enabled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check PyTorch in DeepLabCut ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLabCut is using PyTorch on CPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"DeepLabCut is using PyTorch with GPU support.\")\n",
    "else:\n",
    "    print(\"DeepLabCut is using PyTorch on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by selecting the list of videos to be included in the model. You could manually type the full path of each video in a python list as argument of the deeplabcut.create_new_project() function, like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "Windows users need to use the double backslash for path directories or a python raw filestring.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we use ```tkinter``` to open a file dialoge and save the file paths in a python list called ```videolist```: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_files = filedialog.askopenfilenames(title='Choose new video files to analyze in DeepLabCut:')\n",
    "videolist = list(video_files)\n",
    "\n",
    "print(f'{len(videolist)} videos selected:')\n",
    "for i in range(len(videolist)): \n",
    "    print(videolist[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a new project using the video paths in ```videolist```, give the project a name and set a few parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new DLC Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video exists?  True\n",
      "Working dir exists?  True\n",
      "Created \"/Users/atanugiri/Downloads/DeepLabCutProjects/DLC-BlackFoodAndToyLight-Atanu-2025-08-19/videos\"\n",
      "Created \"/Users/atanugiri/Downloads/DeepLabCutProjects/DLC-BlackFoodAndToyLight-Atanu-2025-08-19/labeled-data\"\n",
      "Created \"/Users/atanugiri/Downloads/DeepLabCutProjects/DLC-BlackFoodAndToyLight-Atanu-2025-08-19/training-datasets\"\n",
      "Created \"/Users/atanugiri/Downloads/DeepLabCutProjects/DLC-BlackFoodAndToyLight-Atanu-2025-08-19/dlc-models\"\n",
      "Copying the videos\n",
      "/Users/atanugiri/Downloads/DeepLabCutProjects/DLC-BlackFoodAndToyLight-Atanu-2025-08-19/videos/ToyLight_10_16_23_P_BlackCement.mp4\n",
      "Generated \"/Users/atanugiri/Downloads/DeepLabCutProjects/DLC-BlackFoodAndToyLight-Atanu-2025-08-19/config.yaml\"\n",
      "\n",
      "A new project with name DLC-BlackFoodAndToyLight-Atanu-2025-08-19 is created at /Users/atanugiri/Downloads/DeepLabCutProjects and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n",
      "Created: /Users/atanugiri/Downloads/DeepLabCutProjects/DLC-BlackFoodAndToyLight-Atanu-2025-08-19/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "video = Path(\"/Users/atanugiri/Downloads/DeepLabCutProjects/data/BlackAnimals/ToyLight/SplitVideos/ToyLight_10_16_23_P_BlackCement.mp4\")\n",
    "working_dir = Path(\"/Users/atanugiri/Downloads/DeepLabCutProjects\")\n",
    "\n",
    "# sanity checks\n",
    "print(\"Video exists? \", video.exists())\n",
    "print(\"Working dir exists? \", working_dir.exists())\n",
    "\n",
    "config_path = deeplabcut.create_new_project(\n",
    "    \"DLC-BlackFoodAndToyLight\",\n",
    "    \"Atanu\",\n",
    "    [str(video)],\n",
    "    working_directory=str(working_dir),\n",
    "    copy_videos=True,\n",
    "    multianimal=False,\n",
    ")\n",
    "print(\"Created:\", config_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "You can load existing DeepLabCut projects by specifying the config_path as below:\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying the videos\n",
      "Copying the videos\n",
      "Copying the videos\n",
      "Copying the videos\n",
      "Copying the videos\n",
      "Copying the videos\n",
      "Copying the videos\n",
      "Copying the videos\n",
      "Copying the videos\n",
      "New videos were added to the project! Use the function 'extract_frames' to select frames for labeling.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "base1 = Path(\"/Users/atanugiri/Downloads/DeepLabCutProjects/data/BlackAnimals/FoodLight/SplitVideos\").expanduser()\n",
    "base2 = Path(\"/Users/atanugiri/Downloads/DeepLabCutProjects/data/BlackAnimals/ToyLight/SplitVideos\").expanduser()\n",
    "\n",
    "names1 = [\n",
    "    \"FoodLight_9_9_24_P_Azul.mp4\",\n",
    "    \"FoodLight_9_9_24_P_Navy.mp4\",\n",
    "    \"FoodLight_9_9_24_P_Tan.mp4\",\n",
    "    \"FoodLight_9_9_24_Y_Cyan.mp4\",\n",
    "    \"FoodLight_9_9_24_Y_Orange.mp4\"\n",
    "]\n",
    "\n",
    "names2 = [\n",
    "    \"ToyLight_10_16_23_P_Flugume.mp4\",\n",
    "    \"ToyLight_10_16_23_P_GammaRay.mp4\",\n",
    "    \"ToyLight_10_16_23_P_OffWhite.mp4\",\n",
    "    \"ToyLight_10_16_23_P_ShatteredBackboard.mp4\"\n",
    "]\n",
    "\n",
    "new_videos = [str(base1 / n) for n in names1] + [str(base2 / n) for n in names2]\n",
    "\n",
    "# add to an existing project:\n",
    "deeplabcut.add_new_videos(config_path, new_videos, copy_videos=True, extract_frames=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Backend (TensorFlow or PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from tensorflow.python.client import device_lib\n",
    "    print(\"Using TensorFlow backend.\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        import torch\n",
    "        print(\"Using PyTorch backend.\")\n",
    "    except ImportError:\n",
    "        print(\"No supported backend found. Ensure TensorFlow or PyTorch is installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that a new project has been created with a specific directory structure and configuration file, we need to tweak some parameters to tailor the bodyparts we want to track:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/atanugiri/Downloads/DeepLabCutProjects/DLC-BlackFoodAndToyLight-Atanu-2025-08-19/config.yaml\n"
     ]
    }
   ],
   "source": [
    "config_path = '/Users/atanugiri/Downloads/DeepLabCutProjects/DLC-BlackFoodAndToyLight-Atanu-2025-08-19/config.yaml'\n",
    "print(config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "webbrowser.open(config_path)\n",
    "print('Please edit bodyparts list to be tracked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_path, 'r') as file:\n",
    "    config_content = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once happy with all ```bodyparts```, ```skeleton:``` and ```numframes2pick:``` settings, start extracting frames to label:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Frames to Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Do you want to extract (perhaps additional) frames for video: /Users/atanugiri/Downloads/DeepLabCutProjects/DLC-BlackFoodAndToyLight-Atanu-2025-08-19/videos/ToyLight_10_16_23_P_BlackCement.mp4 ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n",
      "The directory already contains some frames. Do you want to add to it?(yes/no):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 1366.07  seconds.\n",
      "Do you want to extract (perhaps additional) frames for video: /Users/atanugiri/Downloads/DeepLabCutProjects/DLC-BlackFoodAndToyLight-Atanu-2025-08-19/videos/FoodLight_9_9_24_P_Azul.mp4 ?\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.extract_frames(\n",
    "    config_path, mode='automatic', \n",
    "    algo='uniform', \n",
    "    crop='GUI', # <--- THIS IS KEY: Tells DLC you want to crop\n",
    "    userfeedback=True # <--- THIS IS KEY: Ensures an interactive GUI for selection\n",
    ")\n",
    "\n",
    "# deeplabcut.extract_frames(config_path, \"manual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Frames (Do it in GUI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No supported images were found in /Users/atanugiri/Downloads/DeepLabCutProjects/DLC-BlackFoodAndToyLight-Atanu-2025-08-19/labeled-data/FoodLight_9_9_24_P_Azul.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdeeplabcut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DEEPLABCUT/lib/python3.10/site-packages/deeplabcut/gui/tabs/label_frames.py:98\u001b[0m, in \u001b[0;36mlabel_frames\u001b[0;34m(config_path, image_folder)\u001b[0m\n\u001b[1;32m     95\u001b[0m         image_dir \u001b[38;5;241m=\u001b[39m data_dir \u001b[38;5;241m/\u001b[39m image_folder\n\u001b[1;32m     97\u001b[0m     files \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(image_dir), \u001b[38;5;28mstr\u001b[39m(config_path)]\n\u001b[0;32m---> 98\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mlaunch_napari\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DEEPLABCUT/lib/python3.10/site-packages/deeplabcut/gui/widgets.py:46\u001b[0m, in \u001b[0;36mlaunch_napari\u001b[0;34m(files, plugin, stack)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mviewer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplugin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m viewer\n",
      "File \u001b[0;32m~/miniconda3/envs/DEEPLABCUT/lib/python3.10/site-packages/napari/components/viewer_model.py:1092\u001b[0m, in \u001b[0;36mViewerModel.open\u001b[0;34m(self, path, stack, plugin, layer_type, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m _path \u001b[38;5;241m=\u001b[39m [_path] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_path, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m _path\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plugin:\n\u001b[1;32m   1091\u001b[0m     added\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m-> 1092\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_layers_with_plugins\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m            \u001b[49m\u001b[43mplugin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayer_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m     )\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;66;03m# no plugin choice was made\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m     layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_or_raise_error(\n\u001b[1;32m   1103\u001b[0m         _path, kwargs, layer_type, _stack\n\u001b[1;32m   1104\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/DEEPLABCUT/lib/python3.10/site-packages/napari/components/viewer_model.py:1292\u001b[0m, in \u001b[0;36mViewerModel._add_layers_with_plugins\u001b[0;34m(self, paths, stack, kwargs, plugin, layer_type)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(paths) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1292\u001b[0m     layer_data, hookimpl \u001b[38;5;241m=\u001b[39m \u001b[43mread_data_with_plugins\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplugin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstack\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;66;03m# glean layer names from filename. These will be used as *fallback*\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;66;03m# names, if the plugin does not return a name kwarg in their meta dict.\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m filenames \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/DEEPLABCUT/lib/python3.10/site-packages/napari/plugins/io.py:77\u001b[0m, in \u001b[0;36mread_data_with_plugins\u001b[0;34m(paths, plugin, stack)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(paths) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     75\u001b[0m hookimpl: Optional[HookImplementation]\n\u001b[0;32m---> 77\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_npe2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplugin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     _ld, hookimpl \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/miniconda3/envs/DEEPLABCUT/lib/python3.10/site-packages/napari/plugins/_npe2.py:63\u001b[0m, in \u001b[0;36mread\u001b[0;34m(paths, plugin, stack)\u001b[0m\n\u001b[1;32m     61\u001b[0m     npe1_path \u001b[38;5;241m=\u001b[39m paths[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     layer_data, reader \u001b[38;5;241m=\u001b[39m \u001b[43mio_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_get_reader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnpe1_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplugin_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugin\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# plugin wasn't passed and no reader was found\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo readers returned data\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/miniconda3/envs/DEEPLABCUT/lib/python3.10/site-packages/npe2/io_utils.py:66\u001b[0m, in \u001b[0;36mread_get_reader\u001b[0;34m(path, plugin_name, stack)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stack \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# \"npe1\" old path\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Napari 0.4.15 and older, hopefully we can drop this and make stack mandatory\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     new_path, new_stack \u001b[38;5;241m=\u001b[39m v1_to_v2(path)\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplugin_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugin_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_reader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_stack\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/DEEPLABCUT/lib/python3.10/site-packages/npe2/io_utils.py:165\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(paths, stack, plugin_name, return_reader, _pm)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    161\u001b[0m     chosen_compatible_readers\n\u001b[1;32m    162\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo readers to try. Expected an exception before this point.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rdr \u001b[38;5;129;01min\u001b[39;00m chosen_compatible_readers:\n\u001b[0;32m--> 165\u001b[0m     read_func \u001b[38;5;241m=\u001b[39m \u001b[43mrdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstack\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_registry\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommands\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m read_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;66;03m# if the reader function raises an exception here, we don't try to catch it\u001b[39;00m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m layer_data \u001b[38;5;241m:=\u001b[39m read_func(paths, stack\u001b[38;5;241m=\u001b[39mstack):\n",
      "File \u001b[0;32m~/miniconda3/envs/DEEPLABCUT/lib/python3.10/site-packages/npe2/manifest/contributions/_readers.py:61\u001b[0m, in \u001b[0;36mReaderContribution.exec\u001b[0;34m(self, args, kwargs, _registry)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m stack \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     60\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m v2_to_v1(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m], stack)\n\u001b[0;32m---> 61\u001b[0m callable_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_registry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_registry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DEEPLABCUT/lib/python3.10/site-packages/npe2/manifest/utils.py:61\u001b[0m, in \u001b[0;36mExecutable.exec\u001b[0;34m(self, args, kwargs, _registry)\u001b[0m\n\u001b[1;32m     59\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     60\u001b[0m reg \u001b[38;5;241m=\u001b[39m _registry \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_registry\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DEEPLABCUT/lib/python3.10/site-packages/napari_deeplabcut/_reader.py:77\u001b[0m, in \u001b[0;36mget_folder_parser\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m images:\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo supported images were found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m layers\u001b[38;5;241m.\u001b[39mextend(read_images(images))\n\u001b[1;32m     80\u001b[0m datafile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mOSError\u001b[0m: No supported images were found in /Users/atanugiri/Downloads/DeepLabCutProjects/DLC-BlackFoodAndToyLight-Atanu-2025-08-19/labeled-data/FoodLight_9_9_24_P_Azul."
     ]
    }
   ],
   "source": [
    "deeplabcut.label_frames(config_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot your labeled frames to check your annotation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Atanu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 71.93it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 73.20it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 72.22it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 75.06it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 72.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 73.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 81.84it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 83.68it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 81.20it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 83.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  3,\n",
       "  (array([ 45,  59,   7,  50,  92,  27, 131, 137, 122,   8, 111,  16,  63,\n",
       "           76, 123,  97, 104, 110,  33,  91,  90,  22, 102,  24,   2,  51,\n",
       "           26,  71,  18,  10,  56,  43, 109,  48, 107,  83,  60, 106,  89,\n",
       "           78,  44,  30,  62, 121, 114,  73,  95,  84, 134,  13,  54,  94,\n",
       "          120, 118,  15,  68,  40,  61,  86,  66,   3,  52, 112, 116,   6,\n",
       "          124,  12,  85, 136, 127, 126,  11,  93,  98,  41, 100,   1,  96,\n",
       "          129,  42,   4, 113,  17,  38,   5,  53, 133, 108,   0,  34,  28,\n",
       "           55,  75,  35,  23,  74,  31, 101,  57, 119,  65,  32, 128,  14,\n",
       "          105,  19,  29,  49, 125,  99,  82,  64, 139,  79,  69, 138,  80,\n",
       "          115,  20, 135,  72,  77,  25,  37,  81, 130,  46, 132,  39,  58,\n",
       "           88,  70,  87]),\n",
       "   array([ 36,  21,   9, 103,  67, 117,  47])))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(config_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train The Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training with configuration:\n",
      "data:\n",
      "  bbox_margin: 20\n",
      "  colormode: RGB\n",
      "  inference:\n",
      "    normalize_images: True\n",
      "  train:\n",
      "    affine:\n",
      "      p: 0.5\n",
      "      rotation: 30\n",
      "      scaling: [0.5, 1.25]\n",
      "      translation: 0\n",
      "    crop_sampling:\n",
      "      width: 448\n",
      "      height: 448\n",
      "      max_shift: 0.1\n",
      "      method: hybrid\n",
      "    gaussian_noise: 12.75\n",
      "    motion_blur: True\n",
      "    normalize_images: True\n",
      "device: auto\n",
      "metadata:\n",
      "  project_path: C:\\DeepLabCutProjects\\DLC-WhiteAnimals-Atanu-2025-07-23\n",
      "  pose_config_path: C:\\DeepLabCutProjects\\DLC-WhiteAnimals-Atanu-2025-07-23\\dlc-models-pytorch\\iteration-0\\DLC-WhiteAnimalsJul23-trainset95shuffle3\\train\\pytorch_config.yaml\n",
      "  bodyparts: ['Corner1', 'Corner2', 'Corner3', 'Corner4', 'Head', 'Neck', 'Midback', 'Lowerback', 'Tailbase']\n",
      "  unique_bodyparts: []\n",
      "  individuals: ['animal']\n",
      "  with_identity: None\n",
      "method: bu\n",
      "model:\n",
      "  backbone:\n",
      "    type: ResNet\n",
      "    model_name: resnet50_gn\n",
      "    output_stride: 16\n",
      "    freeze_bn_stats: False\n",
      "    freeze_bn_weights: False\n",
      "  backbone_output_channels: 2048\n",
      "  heads:\n",
      "    bodypart:\n",
      "      type: HeatmapHead\n",
      "      weight_init: normal\n",
      "      predictor:\n",
      "        type: HeatmapPredictor\n",
      "        apply_sigmoid: False\n",
      "        clip_scores: True\n",
      "        location_refinement: True\n",
      "        locref_std: 7.2801\n",
      "      target_generator:\n",
      "        type: HeatmapGaussianGenerator\n",
      "        num_heatmaps: 9\n",
      "        pos_dist_thresh: 17\n",
      "        heatmap_mode: KEYPOINT\n",
      "        gradient_masking: False\n",
      "        generate_locref: True\n",
      "        locref_std: 7.2801\n",
      "      criterion:\n",
      "        heatmap:\n",
      "          type: WeightedMSECriterion\n",
      "          weight: 1.0\n",
      "        locref:\n",
      "          type: WeightedHuberCriterion\n",
      "          weight: 0.05\n",
      "      heatmap_config:\n",
      "        channels: [2048, 9]\n",
      "        kernel_size: [3]\n",
      "        strides: [2]\n",
      "      locref_config:\n",
      "        channels: [2048, 18]\n",
      "        kernel_size: [3]\n",
      "        strides: [2]\n",
      "net_type: resnet_50\n",
      "runner:\n",
      "  type: PoseTrainingRunner\n",
      "  gpus: None\n",
      "  key_metric: test.rmse\n",
      "  key_metric_asc: False\n",
      "  eval_interval: 10\n",
      "  optimizer:\n",
      "    type: AdamW\n",
      "    params:\n",
      "      lr: 0.0005\n",
      "  scheduler:\n",
      "    type: LRListScheduler\n",
      "    params:\n",
      "      lr_list: [[0.0001], [1e-05]]\n",
      "      milestones: [90, 120]\n",
      "  snapshots:\n",
      "    max_snapshots: 5\n",
      "    save_epochs: 5\n",
      "    save_optimizer_state: False\n",
      "train_settings:\n",
      "  batch_size: 8\n",
      "  dataloader_workers: 0\n",
      "  dataloader_pin_memory: False\n",
      "  display_iters: 100\n",
      "  epochs: 200\n",
      "  seed: 42\n",
      "Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)\n",
      "[timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "Data Transforms:\n",
      "  Training:   Compose([\n",
      "  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (0.5, 1.25), 'y': (0.5, 1.25)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),\n",
      "  PadIfNeeded(always_apply=True, p=1.0, min_height=448, min_width=448, pad_height_divisor=None, pad_width_divisor=None, position=PositionType.CENTER, border_mode=0, value=None, mask_value=None),\n",
      "  KeypointAwareCrop(always_apply=True, p=1.0, width=448, height=448, max_shift=0.1, crop_sampling='hybrid'),\n",
      "  MotionBlur(always_apply=False, p=0.5, blur_limit=(3, 7), allow_shifted=True),\n",
      "  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),\n",
      "  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n",
      "], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)\n",
      "  Validation: Compose([\n",
      "  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n",
      "], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)\n",
      "Using 133 images and 7 for testing\n",
      "\n",
      "Starting pose model training...\n",
      "--------------------------------------------------\n",
      "Epoch 1/200 (lr=0.0005), train loss 0.01532\n",
      "Epoch 2/200 (lr=0.0005), train loss 0.01081\n",
      "Epoch 3/200 (lr=0.0005), train loss 0.00776\n",
      "Epoch 4/200 (lr=0.0005), train loss 0.00621\n",
      "Epoch 5/200 (lr=0.0005), train loss 0.00590\n",
      "Epoch 6/200 (lr=0.0005), train loss 0.00462\n",
      "Epoch 7/200 (lr=0.0005), train loss 0.00410\n",
      "Epoch 8/200 (lr=0.0005), train loss 0.00475\n",
      "Epoch 9/200 (lr=0.0005), train loss 0.00385\n",
      "Training for epoch 10 done, starting evaluation\n",
      "Epoch 10/200 (lr=0.0005), train loss 0.00432, valid loss 0.00769\n",
      "Model performance:\n",
      "  metrics/test.rmse:          52.72\n",
      "  metrics/test.rmse_pcutoff:   1.43\n",
      "  metrics/test.mAP:           51.18\n",
      "  metrics/test.mAR:           60.00\n",
      "Epoch 11/200 (lr=0.0005), train loss 0.00352\n",
      "Epoch 12/200 (lr=0.0005), train loss 0.00369\n",
      "Epoch 13/200 (lr=0.0005), train loss 0.00351\n",
      "Epoch 14/200 (lr=0.0005), train loss 0.00275\n",
      "Epoch 15/200 (lr=0.0005), train loss 0.00292\n",
      "Epoch 16/200 (lr=0.0005), train loss 0.00338\n",
      "Epoch 17/200 (lr=0.0005), train loss 0.00281\n",
      "Epoch 18/200 (lr=0.0005), train loss 0.00279\n",
      "Epoch 19/200 (lr=0.0005), train loss 0.00272\n",
      "Training for epoch 20 done, starting evaluation\n",
      "Epoch 20/200 (lr=0.0005), train loss 0.00285, valid loss 0.00774\n",
      "Model performance:\n",
      "  metrics/test.rmse:          69.01\n",
      "  metrics/test.rmse_pcutoff:   3.61\n",
      "  metrics/test.mAP:           49.77\n",
      "  metrics/test.mAR:           54.29\n",
      "Epoch 21/200 (lr=0.0005), train loss 0.00217\n",
      "Epoch 22/200 (lr=0.0005), train loss 0.00233\n",
      "Epoch 23/200 (lr=0.0005), train loss 0.00281\n",
      "Epoch 24/200 (lr=0.0005), train loss 0.00278\n",
      "Epoch 25/200 (lr=0.0005), train loss 0.00270\n",
      "Epoch 26/200 (lr=0.0005), train loss 0.00255\n",
      "Epoch 27/200 (lr=0.0005), train loss 0.00259\n",
      "Epoch 28/200 (lr=0.0005), train loss 0.00250\n",
      "Epoch 29/200 (lr=0.0005), train loss 0.00246\n",
      "Training for epoch 30 done, starting evaluation\n",
      "Epoch 30/200 (lr=0.0005), train loss 0.00209, valid loss 0.00532\n",
      "Model performance:\n",
      "  metrics/test.rmse:          28.75\n",
      "  metrics/test.rmse_pcutoff:   3.79\n",
      "  metrics/test.mAP:           77.92\n",
      "  metrics/test.mAR:           80.00\n",
      "Epoch 31/200 (lr=0.0005), train loss 0.00199\n",
      "Epoch 32/200 (lr=0.0005), train loss 0.00207\n",
      "Epoch 33/200 (lr=0.0005), train loss 0.00243\n",
      "Epoch 34/200 (lr=0.0005), train loss 0.00235\n",
      "Epoch 35/200 (lr=0.0005), train loss 0.00218\n",
      "Epoch 36/200 (lr=0.0005), train loss 0.00254\n",
      "Epoch 37/200 (lr=0.0005), train loss 0.00195\n",
      "Epoch 38/200 (lr=0.0005), train loss 0.00199\n",
      "Epoch 39/200 (lr=0.0005), train loss 0.00174\n",
      "Training for epoch 40 done, starting evaluation\n",
      "Epoch 40/200 (lr=0.0005), train loss 0.00206, valid loss 0.00429\n",
      "Model performance:\n",
      "  metrics/test.rmse:          11.60\n",
      "  metrics/test.rmse_pcutoff:   2.87\n",
      "  metrics/test.mAP:           92.57\n",
      "  metrics/test.mAR:           92.86\n",
      "Epoch 41/200 (lr=0.0005), train loss 0.00174\n",
      "Epoch 42/200 (lr=0.0005), train loss 0.00206\n",
      "Epoch 43/200 (lr=0.0005), train loss 0.00208\n",
      "Epoch 44/200 (lr=0.0005), train loss 0.00181\n",
      "Epoch 45/200 (lr=0.0005), train loss 0.00206\n",
      "Epoch 46/200 (lr=0.0005), train loss 0.00201\n",
      "Epoch 47/200 (lr=0.0005), train loss 0.00227\n",
      "Epoch 48/200 (lr=0.0005), train loss 0.00193\n",
      "Epoch 49/200 (lr=0.0005), train loss 0.00161\n",
      "Training for epoch 50 done, starting evaluation\n",
      "Epoch 50/200 (lr=0.0005), train loss 0.00192, valid loss 0.00462\n",
      "Model performance:\n",
      "  metrics/test.rmse:          12.79\n",
      "  metrics/test.rmse_pcutoff:   3.18\n",
      "  metrics/test.mAP:           92.84\n",
      "  metrics/test.mAR:           94.29\n",
      "Epoch 51/200 (lr=0.0005), train loss 0.00200\n",
      "Epoch 52/200 (lr=0.0005), train loss 0.00166\n",
      "Epoch 53/200 (lr=0.0005), train loss 0.00151\n",
      "Epoch 54/200 (lr=0.0005), train loss 0.00163\n",
      "Epoch 55/200 (lr=0.0005), train loss 0.00210\n",
      "Epoch 56/200 (lr=0.0005), train loss 0.00189\n",
      "Epoch 57/200 (lr=0.0005), train loss 0.00173\n",
      "Epoch 58/200 (lr=0.0005), train loss 0.00190\n",
      "Epoch 59/200 (lr=0.0005), train loss 0.00186\n",
      "Training for epoch 60 done, starting evaluation\n",
      "Epoch 60/200 (lr=0.0005), train loss 0.00145, valid loss 0.00405\n",
      "Model performance:\n",
      "  metrics/test.rmse:          13.45\n",
      "  metrics/test.rmse_pcutoff:   3.08\n",
      "  metrics/test.mAP:           90.50\n",
      "  metrics/test.mAR:           91.43\n",
      "Epoch 61/200 (lr=0.0005), train loss 0.00150\n",
      "Epoch 62/200 (lr=0.0005), train loss 0.00197\n",
      "Epoch 63/200 (lr=0.0005), train loss 0.00116\n",
      "Epoch 64/200 (lr=0.0005), train loss 0.00137\n",
      "Epoch 65/200 (lr=0.0005), train loss 0.00164\n",
      "Epoch 66/200 (lr=0.0005), train loss 0.00144\n",
      "Epoch 67/200 (lr=0.0005), train loss 0.00168\n",
      "Epoch 68/200 (lr=0.0005), train loss 0.00159\n",
      "Epoch 69/200 (lr=0.0005), train loss 0.00147\n",
      "Training for epoch 70 done, starting evaluation\n",
      "Epoch 70/200 (lr=0.0005), train loss 0.00131, valid loss 0.00333\n",
      "Model performance:\n",
      "  metrics/test.rmse:          11.12\n",
      "  metrics/test.rmse_pcutoff:   2.75\n",
      "  metrics/test.mAP:           93.80\n",
      "  metrics/test.mAR:           94.29\n",
      "Epoch 71/200 (lr=0.0005), train loss 0.00184\n",
      "Epoch 72/200 (lr=0.0005), train loss 0.00130\n",
      "Epoch 73/200 (lr=0.0005), train loss 0.00182\n",
      "Epoch 74/200 (lr=0.0005), train loss 0.00134\n",
      "Epoch 75/200 (lr=0.0005), train loss 0.00145\n",
      "Epoch 76/200 (lr=0.0005), train loss 0.00193\n",
      "Epoch 77/200 (lr=0.0005), train loss 0.00139\n",
      "Epoch 78/200 (lr=0.0005), train loss 0.00137\n",
      "Epoch 79/200 (lr=0.0005), train loss 0.00179\n",
      "Training for epoch 80 done, starting evaluation\n",
      "Epoch 80/200 (lr=0.0005), train loss 0.00107, valid loss 0.00341\n",
      "Model performance:\n",
      "  metrics/test.rmse:          10.69\n",
      "  metrics/test.rmse_pcutoff:   2.57\n",
      "  metrics/test.mAP:           92.38\n",
      "  metrics/test.mAR:           94.29\n",
      "Epoch 81/200 (lr=0.0005), train loss 0.00135\n",
      "Epoch 82/200 (lr=0.0005), train loss 0.00162\n",
      "Epoch 83/200 (lr=0.0005), train loss 0.00108\n",
      "Epoch 84/200 (lr=0.0005), train loss 0.00148\n",
      "Epoch 85/200 (lr=0.0005), train loss 0.00142\n",
      "Epoch 86/200 (lr=0.0005), train loss 0.00163\n",
      "Epoch 87/200 (lr=0.0005), train loss 0.00158\n",
      "Epoch 88/200 (lr=0.0005), train loss 0.00131\n",
      "Epoch 89/200 (lr=0.0005), train loss 0.00150\n",
      "Training for epoch 90 done, starting evaluation\n",
      "Epoch 90/200 (lr=0.0001), train loss 0.00174, valid loss 0.00361\n",
      "Model performance:\n",
      "  metrics/test.rmse:          11.46\n",
      "  metrics/test.rmse_pcutoff:   2.56\n",
      "  metrics/test.mAP:           92.87\n",
      "  metrics/test.mAR:           94.29\n",
      "Epoch 91/200 (lr=0.0001), train loss 0.00141\n",
      "Epoch 92/200 (lr=0.0001), train loss 0.00128\n",
      "Epoch 93/200 (lr=0.0001), train loss 0.00118\n",
      "Epoch 94/200 (lr=0.0001), train loss 0.00096\n",
      "Epoch 95/200 (lr=0.0001), train loss 0.00089\n",
      "Epoch 96/200 (lr=0.0001), train loss 0.00108\n",
      "Epoch 97/200 (lr=0.0001), train loss 0.00079\n",
      "Epoch 98/200 (lr=0.0001), train loss 0.00100\n",
      "Epoch 99/200 (lr=0.0001), train loss 0.00100\n",
      "Training for epoch 100 done, starting evaluation\n",
      "Epoch 100/200 (lr=0.0001), train loss 0.00117, valid loss 0.00344\n",
      "Model performance:\n",
      "  metrics/test.rmse:           7.31\n",
      "  metrics/test.rmse_pcutoff:   2.10\n",
      "  metrics/test.mAP:           95.81\n",
      "  metrics/test.mAR:           97.14\n",
      "Epoch 101/200 (lr=0.0001), train loss 0.00090\n",
      "Epoch 102/200 (lr=0.0001), train loss 0.00077\n",
      "Epoch 103/200 (lr=0.0001), train loss 0.00085\n",
      "Epoch 104/200 (lr=0.0001), train loss 0.00093\n",
      "Epoch 105/200 (lr=0.0001), train loss 0.00090\n",
      "Epoch 106/200 (lr=0.0001), train loss 0.00085\n",
      "Epoch 107/200 (lr=0.0001), train loss 0.00109\n",
      "Epoch 108/200 (lr=0.0001), train loss 0.00078\n",
      "Epoch 109/200 (lr=0.0001), train loss 0.00075\n",
      "Training for epoch 110 done, starting evaluation\n",
      "Epoch 110/200 (lr=0.0001), train loss 0.00107, valid loss 0.00339\n",
      "Model performance:\n",
      "  metrics/test.rmse:          11.38\n",
      "  metrics/test.rmse_pcutoff:   2.20\n",
      "  metrics/test.mAP:           92.62\n",
      "  metrics/test.mAR:           94.29\n",
      "Epoch 111/200 (lr=0.0001), train loss 0.00065\n",
      "Epoch 112/200 (lr=0.0001), train loss 0.00073\n",
      "Epoch 113/200 (lr=0.0001), train loss 0.00090\n",
      "Epoch 114/200 (lr=0.0001), train loss 0.00093\n",
      "Epoch 115/200 (lr=0.0001), train loss 0.00079\n",
      "Epoch 116/200 (lr=0.0001), train loss 0.00085\n",
      "Epoch 117/200 (lr=0.0001), train loss 0.00081\n",
      "Epoch 118/200 (lr=0.0001), train loss 0.00075\n",
      "Epoch 119/200 (lr=0.0001), train loss 0.00089\n",
      "Training for epoch 120 done, starting evaluation\n",
      "Epoch 120/200 (lr=1e-05), train loss 0.00078, valid loss 0.00330\n",
      "Model performance:\n",
      "  metrics/test.rmse:          11.47\n",
      "  metrics/test.rmse_pcutoff:   2.40\n",
      "  metrics/test.mAP:           92.62\n",
      "  metrics/test.mAR:           94.29\n",
      "Epoch 121/200 (lr=1e-05), train loss 0.00087\n",
      "Epoch 122/200 (lr=1e-05), train loss 0.00080\n",
      "Epoch 123/200 (lr=1e-05), train loss 0.00079\n",
      "Epoch 124/200 (lr=1e-05), train loss 0.00083\n",
      "Epoch 125/200 (lr=1e-05), train loss 0.00066\n",
      "Epoch 126/200 (lr=1e-05), train loss 0.00077\n",
      "Epoch 127/200 (lr=1e-05), train loss 0.00089\n",
      "Epoch 128/200 (lr=1e-05), train loss 0.00060\n",
      "Epoch 129/200 (lr=1e-05), train loss 0.00076\n",
      "Training for epoch 130 done, starting evaluation\n",
      "Epoch 130/200 (lr=1e-05), train loss 0.00071, valid loss 0.00330\n",
      "Model performance:\n",
      "  metrics/test.rmse:          14.79\n",
      "  metrics/test.rmse_pcutoff:   2.41\n",
      "  metrics/test.mAP:           90.89\n",
      "  metrics/test.mAR:           91.43\n",
      "Epoch 131/200 (lr=1e-05), train loss 0.00091\n",
      "Epoch 132/200 (lr=1e-05), train loss 0.00060\n",
      "Epoch 133/200 (lr=1e-05), train loss 0.00083\n",
      "Epoch 134/200 (lr=1e-05), train loss 0.00073\n",
      "Epoch 135/200 (lr=1e-05), train loss 0.00078\n",
      "Epoch 136/200 (lr=1e-05), train loss 0.00086\n",
      "Epoch 137/200 (lr=1e-05), train loss 0.00078\n",
      "Epoch 138/200 (lr=1e-05), train loss 0.00087\n",
      "Epoch 139/200 (lr=1e-05), train loss 0.00077\n",
      "Training for epoch 140 done, starting evaluation\n",
      "Epoch 140/200 (lr=1e-05), train loss 0.00077, valid loss 0.00328\n",
      "Model performance:\n",
      "  metrics/test.rmse:          15.03\n",
      "  metrics/test.rmse_pcutoff:   2.46\n",
      "  metrics/test.mAP:           90.89\n",
      "  metrics/test.mAR:           91.43\n",
      "Epoch 141/200 (lr=1e-05), train loss 0.00082\n",
      "Epoch 142/200 (lr=1e-05), train loss 0.00066\n",
      "Epoch 143/200 (lr=1e-05), train loss 0.00071\n",
      "Epoch 144/200 (lr=1e-05), train loss 0.00078\n",
      "Epoch 145/200 (lr=1e-05), train loss 0.00072\n",
      "Epoch 146/200 (lr=1e-05), train loss 0.00084\n",
      "Epoch 147/200 (lr=1e-05), train loss 0.00076\n",
      "Epoch 148/200 (lr=1e-05), train loss 0.00077\n",
      "Epoch 149/200 (lr=1e-05), train loss 0.00074\n",
      "Training for epoch 150 done, starting evaluation\n",
      "Epoch 150/200 (lr=1e-05), train loss 0.00087, valid loss 0.00325\n",
      "Model performance:\n",
      "  metrics/test.rmse:          14.80\n",
      "  metrics/test.rmse_pcutoff:   2.43\n",
      "  metrics/test.mAP:           90.89\n",
      "  metrics/test.mAR:           91.43\n",
      "Epoch 151/200 (lr=1e-05), train loss 0.00099\n",
      "Epoch 152/200 (lr=1e-05), train loss 0.00074\n",
      "Epoch 153/200 (lr=1e-05), train loss 0.00072\n",
      "Epoch 154/200 (lr=1e-05), train loss 0.00070\n",
      "Epoch 155/200 (lr=1e-05), train loss 0.00077\n",
      "Epoch 156/200 (lr=1e-05), train loss 0.00066\n",
      "Epoch 157/200 (lr=1e-05), train loss 0.00084\n",
      "Epoch 158/200 (lr=1e-05), train loss 0.00071\n",
      "Epoch 159/200 (lr=1e-05), train loss 0.00073\n",
      "Training for epoch 160 done, starting evaluation\n",
      "Epoch 160/200 (lr=1e-05), train loss 0.00084, valid loss 0.00327\n",
      "Model performance:\n",
      "  metrics/test.rmse:          11.32\n",
      "  metrics/test.rmse_pcutoff:   2.44\n",
      "  metrics/test.mAP:           92.87\n",
      "  metrics/test.mAR:           94.29\n",
      "Epoch 161/200 (lr=1e-05), train loss 0.00084\n",
      "Epoch 162/200 (lr=1e-05), train loss 0.00078\n",
      "Epoch 163/200 (lr=1e-05), train loss 0.00084\n",
      "Epoch 164/200 (lr=1e-05), train loss 0.00070\n",
      "Epoch 165/200 (lr=1e-05), train loss 0.00089\n",
      "Epoch 166/200 (lr=1e-05), train loss 0.00055\n",
      "Epoch 167/200 (lr=1e-05), train loss 0.00063\n",
      "Epoch 168/200 (lr=1e-05), train loss 0.00069\n",
      "Epoch 169/200 (lr=1e-05), train loss 0.00074\n",
      "Training for epoch 170 done, starting evaluation\n",
      "Epoch 170/200 (lr=1e-05), train loss 0.00093, valid loss 0.00320\n",
      "Model performance:\n",
      "  metrics/test.rmse:          11.29\n",
      "  metrics/test.rmse_pcutoff:   2.38\n",
      "  metrics/test.mAP:           92.87\n",
      "  metrics/test.mAR:           94.29\n",
      "Epoch 171/200 (lr=1e-05), train loss 0.00083\n",
      "Epoch 172/200 (lr=1e-05), train loss 0.00061\n",
      "Epoch 173/200 (lr=1e-05), train loss 0.00067\n",
      "Epoch 174/200 (lr=1e-05), train loss 0.00067\n",
      "Epoch 175/200 (lr=1e-05), train loss 0.00056\n",
      "Epoch 176/200 (lr=1e-05), train loss 0.00097\n",
      "Epoch 177/200 (lr=1e-05), train loss 0.00075\n",
      "Epoch 178/200 (lr=1e-05), train loss 0.00068\n",
      "Epoch 179/200 (lr=1e-05), train loss 0.00076\n",
      "Training for epoch 180 done, starting evaluation\n",
      "Epoch 180/200 (lr=1e-05), train loss 0.00093, valid loss 0.00325\n",
      "Model performance:\n",
      "  metrics/test.rmse:          11.36\n",
      "  metrics/test.rmse_pcutoff:   2.38\n",
      "  metrics/test.mAP:           92.62\n",
      "  metrics/test.mAR:           94.29\n",
      "Epoch 181/200 (lr=1e-05), train loss 0.00093\n",
      "Epoch 182/200 (lr=1e-05), train loss 0.00055\n",
      "Epoch 183/200 (lr=1e-05), train loss 0.00088\n",
      "Epoch 184/200 (lr=1e-05), train loss 0.00088\n",
      "Epoch 185/200 (lr=1e-05), train loss 0.00076\n",
      "Epoch 186/200 (lr=1e-05), train loss 0.00074\n",
      "Epoch 187/200 (lr=1e-05), train loss 0.00065\n",
      "Epoch 188/200 (lr=1e-05), train loss 0.00061\n",
      "Epoch 189/200 (lr=1e-05), train loss 0.00059\n",
      "Training for epoch 190 done, starting evaluation\n",
      "Epoch 190/200 (lr=1e-05), train loss 0.00062, valid loss 0.00333\n",
      "Model performance:\n",
      "  metrics/test.rmse:          11.36\n",
      "  metrics/test.rmse_pcutoff:   2.42\n",
      "  metrics/test.mAP:           92.62\n",
      "  metrics/test.mAR:           94.29\n",
      "Epoch 191/200 (lr=1e-05), train loss 0.00059\n",
      "Epoch 192/200 (lr=1e-05), train loss 0.00083\n",
      "Epoch 193/200 (lr=1e-05), train loss 0.00052\n",
      "Epoch 194/200 (lr=1e-05), train loss 0.00085\n",
      "Epoch 195/200 (lr=1e-05), train loss 0.00074\n",
      "Epoch 196/200 (lr=1e-05), train loss 0.00064\n",
      "Epoch 197/200 (lr=1e-05), train loss 0.00083\n",
      "Epoch 198/200 (lr=1e-05), train loss 0.00071\n",
      "Epoch 199/200 (lr=1e-05), train loss 0.00080\n",
      "Training for epoch 200 done, starting evaluation\n",
      "Epoch 200/200 (lr=1e-05), train loss 0.00088, valid loss 0.00325\n",
      "Model performance:\n",
      "  metrics/test.rmse:          11.34\n",
      "  metrics/test.rmse_pcutoff:   2.41\n",
      "  metrics/test.mAP:           92.87\n",
      "  metrics/test.mAR:           94.29\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(\n",
    "    config_path,\n",
    "    shuffle=3,\n",
    "    trainingsetindex=0,\n",
    "    device=\"cuda:0\",\n",
    "    max_snapshots_to_keep=5,\n",
    "    displayiters=100,\n",
    "    save_epochs=5,\n",
    "    epochs=200,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Trained Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 133/133 [00:02<00:00, 47.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 50.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle2_snapshot_200-results.csv (pcutoff: 0.3):\n",
      "train rmse            45.36\n",
      "train rmse_pcutoff     3.38\n",
      "train mAP             59.74\n",
      "train mAR             68.42\n",
      "test rmse             44.46\n",
      "test rmse_pcutoff      8.18\n",
      "test mAP              63.89\n",
      "test mAR              72.86\n",
      "Name: (0.95, 2, 200, -1, 0.3), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(config_path, Shuffles=[3], plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze new Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing videos with C:\\DeepLabCutProjects\\DLC-WhiteAnimals-Atanu-2025-07-23\\dlc-models-pytorch\\iteration-0\\DLC-WhiteAnimalsJul23-trainset95shuffle3\\train\\snapshot-best-100.pt\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\Test\\ToyOnly_2_25_25_S1P_Dallas_trimmed.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    2417\n",
      "  Duration of video [s]:  96.72\n",
      "  fps:                    24.99\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2417/2417 [00:55<00:00, 43.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\Test\\ToyOnly_2_25_25_S1P_Dallas_trimmedDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\Test\\ToyOnly_2_25_25_S1P_Dallas_trimmedDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_J_trimmed.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    2390\n",
      "  Duration of video [s]:  95.64\n",
      "  fps:                    24.99\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 2389/2390 [00:56<00:00, 42.42it/s]\n",
      "WARNING:root:The video metadata indicates that there 2390 in the video, but only 2389 were able to be processed. This can happen if the video is corrupted. You can try to fix the issue by re-encoding your video (tips on how to do that: https://deeplabcut.github.io/DeepLabCut/docs/recipes/io.html#tips-on-video-re-encoding-and-preprocessing)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_J_trimmedDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_J_trimmedDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_K_trimmed.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    2334\n",
      "  Duration of video [s]:  93.40\n",
      "  fps:                    24.99\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2334/2334 [00:56<00:00, 41.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_K_trimmedDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_K_trimmedDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "The videos are analyzed. Now your research can truly start!\n",
      "You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videolist = [r\"C:\\DeepLabCutProjects\\data\\Test\\ToyOnly_2_25_25_S1P_Dallas_trimmed.mp4\",\n",
    "            r\"C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_J_trimmed.mp4\",\n",
    "            r\"C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_K_trimmed.mp4\"]\n",
    "# destfolder = r\"C:\\DeepLabCutProjects\\data\\FoodLight\\DlcDataPytorch\"\n",
    "\n",
    "deeplabcut.analyze_videos(config_path, videos=videolist, shuffle=3, gputouse=\"cuda:0\", save_as_csv=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All videos in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: ToyOnlyWhite\n",
      "Analyzing 47 videos, saving to C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\n",
      "Analyzing videos with C:\\DeepLabCutProjects\\DLC-WhiteAnimals-Atanu-2025-07-23\\dlc-models-pytorch\\iteration-0\\DLC-WhiteAnimalsJul23-trainset95shuffle3\\train\\snapshot-best-100.pt\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S1Y_Doc.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyExcitatory_2_26_25_S1Y_DocDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S1Y_Dopey.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyExcitatory_2_26_25_S1Y_DopeyDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S1Y_Grumpy.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyExcitatory_2_26_25_S1Y_GrumpyDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S1Y_Sneezy.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyExcitatory_2_26_25_S1Y_SneezyDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S2Y_Bashful.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyExcitatory_2_26_25_S2Y_BashfulDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S2Y_Happy.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyExcitatory_2_26_25_S2Y_HappyDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S2Y_Sleepy.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyExcitatory_2_26_25_S2Y_SleepyDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S3Y_Roy.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyExcitatory_2_26_25_S3Y_RoyDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S3Y_Sam.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyExcitatory_2_26_25_S3Y_SamDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S4Y_Ivy.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyExcitatory_2_26_25_S4Y_IvyDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S4Y_May.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyExcitatory_2_26_25_S4Y_MayDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S1P_A.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyInhibitory_2_27_25_S1P_ADLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S1P_B.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyInhibitory_2_27_25_S1P_BDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S1P_C.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyInhibitory_2_27_25_S1P_CDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S1P_F.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyInhibitory_2_27_25_S1P_FDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S2P_E.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyInhibitory_2_27_25_S2P_EDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S2P_G.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyInhibitory_2_27_25_S2P_GDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S2P_H.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyInhibitory_2_27_25_S2P_HDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S2P_L.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyInhibitory_2_27_25_S2P_LDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S3P_I.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyInhibitory_2_27_25_S3P_IDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S3P_J.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyInhibitory_2_27_25_S3P_JDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S3P_K.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyInhibitory_2_27_25_S3P_KDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S3P_O.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyInhibitory_2_27_25_S3P_ODLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S4P_M.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyInhibitory_2_27_25_S4P_MDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S4P_P.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyInhibitory_2_27_25_S4P_PDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S4P_Q.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnlyInhibitory_2_27_25_S4P_QDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S1P_Dallas.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_2_25_25_S1P_DallasDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S1P_FtWorth.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_2_25_25_S1P_FtWorthDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S1P_Orlando.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_2_25_25_S1P_OrlandoDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S1P_Tampa.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_2_25_25_S1P_TampaDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S2P_Chicago.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_2_25_25_S2P_ChicagoDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S2P_LA.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_2_25_25_S2P_LADLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S2P_LasCruces.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_2_25_25_S2P_LasCrucesDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S2P_Seattle.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_2_25_25_S2P_SeattleDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S3P_Atlanta.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_2_25_25_S3P_AtlantaDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S3P_NewOrleans.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_2_25_25_S3P_NewOrleansDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S3P_Ruidoso.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_2_25_25_S3P_RuidosoDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S3P_Tokyo.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_2_25_25_S3P_TokyoDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S4P_NewJersey.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_2_25_25_S4P_NewJerseyDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S4P_NewYork.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_2_25_25_S4P_NewYorkDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S1Y_Austin.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_3_4_25_S1Y_AustinDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S1Y_Berlin.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_3_4_25_S1Y_BerlinDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S1Y_Houston.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_3_4_25_S1Y_HoustonDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S1Y_Toronto.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_3_4_25_S1Y_TorontoDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S4Y_London.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_3_4_25_S4Y_LondonDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S4Y_Paris.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_3_4_25_S4Y_ParisDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S4Y_Phoenix.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\DlcDataPytorch\\ToyOnly_3_4_25_S4Y_PhoenixDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "The videos are analyzed. Now your research can truly start!\n",
      "You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "\n",
      "\n",
      "Processing: ToyLightWhite\n",
      "Analyzing 46 videos, saving to C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\n",
      "Analyzing videos with C:\\DeepLabCutProjects\\DLC-WhiteAnimals-Atanu-2025-07-23\\dlc-models-pytorch\\iteration-0\\DLC-WhiteAnimalsJul23-trainset95shuffle3\\train\\snapshot-best-100.pt\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightExcitatory_2_24_25_S1Y_Doc.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightExcitatory_2_24_25_S1Y_DocDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightExcitatory_2_24_25_S1Y_Dopey.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightExcitatory_2_24_25_S1Y_DopeyDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightExcitatory_2_24_25_S1Y_Grumpy.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightExcitatory_2_24_25_S1Y_GrumpyDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightExcitatory_2_24_25_S1Y_Sneezy.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightExcitatory_2_24_25_S1Y_SneezyDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Video C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightExcitatory_2_24_25_S2Y_Bashful.mp4 already analyzed at C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightExcitatory_2_24_25_S2Y_BashfulDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle!\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightExcitatory_2_24_25_S2Y_Happy.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30017\n",
      "  Duration of video [s]:  1200.68\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30017/30017 [12:00<00:00, 41.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightExcitatory_2_24_25_S2Y_HappyDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightExcitatory_2_24_25_S2Y_HappyDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightExcitatory_2_24_25_S2Y_Sleepy.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30017\n",
      "  Duration of video [s]:  1200.68\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30017/30017 [12:10<00:00, 41.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightExcitatory_2_24_25_S2Y_SleepyDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightExcitatory_2_24_25_S2Y_SleepyDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightInhibitory_1_22_25_S1P_A.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30015\n",
      "  Duration of video [s]:  1200.60\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30015/30015 [12:13<00:00, 40.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S1P_ADLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S1P_ADLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightInhibitory_1_22_25_S1P_B.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30015\n",
      "  Duration of video [s]:  1200.60\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30015/30015 [12:13<00:00, 40.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S1P_BDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S1P_BDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightInhibitory_1_22_25_S1P_C.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30015\n",
      "  Duration of video [s]:  1200.60\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30015/30015 [12:14<00:00, 40.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S1P_CDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S1P_CDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightInhibitory_1_22_25_S1P_F.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30015\n",
      "  Duration of video [s]:  1200.60\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30015/30015 [12:16<00:00, 40.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S1P_FDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S1P_FDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightInhibitory_1_22_25_S2P_E.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30020\n",
      "  Duration of video [s]:  1200.80\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30020/30020 [12:07<00:00, 41.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S2P_EDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S2P_EDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightInhibitory_1_22_25_S2P_G.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30020\n",
      "  Duration of video [s]:  1200.80\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30020/30020 [12:04<00:00, 41.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S2P_GDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S2P_GDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightInhibitory_1_22_25_S2P_H.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30020\n",
      "  Duration of video [s]:  1200.80\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30020/30020 [12:04<00:00, 41.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S2P_HDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S2P_HDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightInhibitory_1_22_25_S2P_L.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30020\n",
      "  Duration of video [s]:  1200.80\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30020/30020 [12:04<00:00, 41.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S2P_LDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S2P_LDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightInhibitory_1_22_25_S3P_I.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30017\n",
      "  Duration of video [s]:  1200.68\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30017/30017 [12:04<00:00, 41.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S3P_IDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S3P_IDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightInhibitory_1_22_25_S3P_J.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30017\n",
      "  Duration of video [s]:  1200.68\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30017/30017 [12:03<00:00, 41.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S3P_JDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S3P_JDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightInhibitory_1_22_25_S3P_K.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30017\n",
      "  Duration of video [s]:  1200.68\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30017/30017 [12:04<00:00, 41.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S3P_KDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S3P_KDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightInhibitory_1_22_25_S3P_O.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30017\n",
      "  Duration of video [s]:  1200.68\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30017/30017 [12:03<00:00, 41.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S3P_ODLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S3P_ODLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightInhibitory_1_22_25_S4P_M.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30015\n",
      "  Duration of video [s]:  1200.60\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30015/30015 [12:03<00:00, 41.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S4P_MDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S4P_MDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightInhibitory_1_22_25_S4P_P.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30015\n",
      "  Duration of video [s]:  1200.60\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30015/30015 [12:04<00:00, 41.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S4P_PDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S4P_PDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLightInhibitory_1_22_25_S4P_Q.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30015\n",
      "  Duration of video [s]:  1200.60\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30015/30015 [12:03<00:00, 41.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S4P_QDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLightInhibitory_1_22_25_S4P_QDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_1_21_25_S1P_Dallas.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30016\n",
      "  Duration of video [s]:  1200.64\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30016/30016 [12:04<00:00, 41.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S1P_DallasDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S1P_DallasDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_1_21_25_S1P_FtWorth.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30016\n",
      "  Duration of video [s]:  1200.64\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30016/30016 [12:11<00:00, 41.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S1P_FtWorthDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S1P_FtWorthDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_1_21_25_S1P_Orlando.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30016\n",
      "  Duration of video [s]:  1200.64\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 30016/30016 [1:44:13<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S1P_OrlandoDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S1P_OrlandoDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_1_21_25_S1P_Tampa.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30016\n",
      "  Duration of video [s]:  1200.64\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30016/30016 [11:59<00:00, 41.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S1P_TampaDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S1P_TampaDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_1_21_25_S2P_Chicago.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30016\n",
      "  Duration of video [s]:  1200.64\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30016/30016 [11:56<00:00, 41.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S2P_ChicagoDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S2P_ChicagoDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_1_21_25_S2P_LA.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30016\n",
      "  Duration of video [s]:  1200.64\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30016/30016 [11:57<00:00, 41.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S2P_LADLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S2P_LADLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_1_21_25_S2P_LasCruces.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30016\n",
      "  Duration of video [s]:  1200.64\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30016/30016 [11:57<00:00, 41.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S2P_LasCrucesDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S2P_LasCrucesDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_1_21_25_S2P_Seattle.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30016\n",
      "  Duration of video [s]:  1200.64\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30016/30016 [11:57<00:00, 41.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S2P_SeattleDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S2P_SeattleDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_1_21_25_S3P_Atlanta.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30016\n",
      "  Duration of video [s]:  1200.64\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30016/30016 [11:57<00:00, 41.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S3P_AtlantaDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S3P_AtlantaDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_1_21_25_S3P_NewOrleans.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30016\n",
      "  Duration of video [s]:  1200.64\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30016/30016 [11:56<00:00, 41.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S3P_NewOrleansDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S3P_NewOrleansDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_1_21_25_S3P_Ruidoso.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30016\n",
      "  Duration of video [s]:  1200.64\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30016/30016 [11:57<00:00, 41.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S3P_RuidosoDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S3P_RuidosoDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_1_21_25_S3P_Tokyo.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30016\n",
      "  Duration of video [s]:  1200.64\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30016/30016 [11:56<00:00, 41.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S3P_TokyoDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S3P_TokyoDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_1_21_25_S4P_NewJersey.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30016\n",
      "  Duration of video [s]:  1200.64\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30016/30016 [11:57<00:00, 41.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S4P_NewJerseyDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S4P_NewJerseyDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_1_21_25_S4P_NewYork.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30016\n",
      "  Duration of video [s]:  1200.64\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30016/30016 [11:59<00:00, 41.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S4P_NewYorkDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_1_21_25_S4P_NewYorkDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_2_5_25_S1Y_3.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30017\n",
      "  Duration of video [s]:  1200.68\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30017/30017 [11:56<00:00, 41.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_5_25_S1Y_3DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_5_25_S1Y_3DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_2_5_25_S1Y_4.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30017\n",
      "  Duration of video [s]:  1200.68\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30017/30017 [11:54<00:00, 41.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_5_25_S1Y_4DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_5_25_S1Y_4DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_2_5_25_S2Y_7.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30016\n",
      "  Duration of video [s]:  1200.64\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30016/30016 [11:57<00:00, 41.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_5_25_S2Y_7DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_5_25_S2Y_7DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_2_5_25_S2Y_8.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30016\n",
      "  Duration of video [s]:  1200.64\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30016/30016 [11:55<00:00, 41.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_5_25_S2Y_8DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_5_25_S2Y_8DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_2_5_25_S3Y_10.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30017\n",
      "  Duration of video [s]:  1200.68\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30017/30017 [11:57<00:00, 41.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_5_25_S3Y_10DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_5_25_S3Y_10DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_2_7_25_S1Y_1.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30016\n",
      "  Duration of video [s]:  1200.64\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30016/30016 [11:56<00:00, 41.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_7_25_S1Y_1DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_7_25_S1Y_1DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_2_7_25_S1Y_2.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30016\n",
      "  Duration of video [s]:  1200.64\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30016/30016 [11:56<00:00, 41.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_7_25_S1Y_2DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_7_25_S1Y_2DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_2_7_25_S2Y_5.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30020\n",
      "  Duration of video [s]:  1200.80\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30020/30020 [11:57<00:00, 41.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_7_25_S2Y_5DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_7_25_S2Y_5DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_2_7_25_S2Y_6.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30020\n",
      "  Duration of video [s]:  1200.80\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30020/30020 [11:56<00:00, 41.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_7_25_S2Y_6DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_7_25_S2Y_6DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "Starting to analyze C:\\DeepLabCutProjects\\data\\ToyLightWhite\\SplitVideos\\ToyLight_2_7_25_S3Y_9.mp4\n",
      "Video metadata: \n",
      "  Overall # of frames:    30020\n",
      "  Duration of video [s]:  1200.80\n",
      "  fps:                    25.0\n",
      "  resolution:             w=360, h=288\n",
      "\n",
      "Running pose prediction with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30020/30020 [11:56<00:00, 41.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_7_25_S3Y_9DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100.h5 and C:\\DeepLabCutProjects\\data\\ToyLightWhite\\DlcDataPytorch\\ToyLight_2_7_25_S3Y_9DLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_full.pickle\n",
      "The videos are analyzed. Now your research can truly start!\n",
      "You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "\n",
      "\n",
      "All batches submitted for analysis.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# base data path\n",
    "base_path = r\"C:\\DeepLabCutProjects\\data\"\n",
    "\n",
    "# List of subfolders to process\n",
    "conditions = ['ToyOnlyWhite', 'ToyLightWhite']\n",
    "\n",
    "# Loop over all conditions\n",
    "for condition in conditions:\n",
    "    print(f\"\\nProcessing: {condition}\")\n",
    "\n",
    "    video_dir = os.path.join(base_path, condition, \"SplitVideos\")\n",
    "    destfolder = os.path.join(base_path, condition, \"DlcDataPytorch\")\n",
    "    os.makedirs(destfolder, exist_ok=True)\n",
    "\n",
    "    # Get list of video files\n",
    "    videolist = [\n",
    "        os.path.join(video_dir, f)\n",
    "        for f in os.listdir(video_dir)\n",
    "        if f.endswith(('.mp4', '.avi'))\n",
    "    ]\n",
    "\n",
    "    # Skip if no videos\n",
    "    if not videolist:\n",
    "        print(f\"No videos found in {video_dir}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Analyze\n",
    "    print(f\"Analyzing {len(videolist)} videos, saving to {destfolder}\")\n",
    "    deeplabcut.analyze_videos(\n",
    "        config_path,\n",
    "        videos=videolist,\n",
    "        shuffle=3,\n",
    "        gputouse=\"cuda:0\",\n",
    "        save_as_csv=True,\n",
    "        destfolder=destfolder\n",
    "    )\n",
    "\n",
    "print(\"\\nAll batches submitted for analysis.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Pose Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering with median model C:\\DeepLabCutProjects\\data\\Test\\ToyOnly_2_25_25_S1P_Dallas_trimmed.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_J_trimmed.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_K_trimmed.mp4\n",
      "Saving filtered csv poses!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.filterpredictions(config_path, videolist, shuffle=3, filtertype='median', p_bound=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All videos in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: ToyOnlyWhite\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S1Y_Doc.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S1Y_Dopey.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S1Y_Grumpy.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S1Y_Sneezy.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S2Y_Bashful.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S2Y_Happy.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S2Y_Sleepy.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S3Y_Roy.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S3Y_Sam.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S4Y_Ivy.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyExcitatory_2_26_25_S4Y_May.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S1P_A.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S1P_B.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S1P_C.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S1P_F.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S2P_E.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S2P_G.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S2P_H.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S2P_L.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S3P_I.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S3P_J.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S3P_K.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S3P_O.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S4P_M.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S4P_P.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnlyInhibitory_2_27_25_S4P_Q.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S1P_Dallas.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S1P_FtWorth.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S1P_Orlando.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S1P_Tampa.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S2P_Chicago.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S2P_LA.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S2P_LasCruces.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S2P_Seattle.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S3P_Atlanta.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S3P_NewOrleans.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S3P_Ruidoso.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S3P_Tokyo.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S4P_NewJersey.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_2_25_25_S4P_NewYork.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S1Y_Austin.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S1Y_Berlin.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S1Y_Houston.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S1Y_Toronto.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S4Y_London.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S4Y_Paris.mp4\n",
      "Saving filtered csv poses!\n",
      "Filtering with median model C:\\DeepLabCutProjects\\data\\ToyOnlyWhite\\SplitVideos\\ToyOnly_3_4_25_S4Y_Phoenix.mp4\n",
      "Saving filtered csv poses!\n",
      "\n",
      "All batches submitted for analysis.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# base data path\n",
    "base_path = r\"C:\\DeepLabCutProjects\\data\"\n",
    "\n",
    "# List of subfolders to process\n",
    "conditions = ['ToyOnlyWhite']\n",
    "\n",
    "# Loop over all conditions\n",
    "for condition in conditions:\n",
    "    print(f\"\\nProcessing: {condition}\")\n",
    "\n",
    "    video_dir = os.path.join(base_path, condition, \"SplitVideos\")\n",
    "\n",
    "    # Get list of video files\n",
    "    videolist = [\n",
    "        os.path.join(video_dir, f)\n",
    "        for f in os.listdir(video_dir)\n",
    "        if f.endswith(('.mp4', '.avi'))\n",
    "    ]\n",
    "\n",
    "    # Skip if no videos\n",
    "    if not videolist:\n",
    "        print(f\"No videos found in {video_dir}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Analyze\n",
    "    deeplabcut.filterpredictions(\n",
    "        config_path,\n",
    "        videolist,\n",
    "        shuffle=3,\n",
    "        save_as_csv=True\n",
    "    )\n",
    "\n",
    "print(\"\\nAll batches submitted for analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "deeplabcut.analyzeskeleton(config_path, videolist, videotype='.mp4', shuffle=1, trainingsetindex=0, save_as_csv=False, destfolder=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create labeled videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:matplotlib.animation:MovieWriter._run: running command: ffmpeg -f rawvideo -vcodec rawvideo -s 360x288 -pix_fmt rgba -framerate 24.9852410891309 -loglevel error -i pipe: -vcodec h264 -pix_fmt yuv420p -y 'C:\\DeepLabCutProjects\\data\\Test\\ToyOnly_2_25_25_S1P_Dallas_trimmedDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_filtered_p30_labeled.mp4'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process video: C:\\DeepLabCutProjects\\data\\Test\\ToyOnly_2_25_25_S1P_Dallas_trimmed.mp4\n",
      "Loading C:\\DeepLabCutProjects\\data\\Test\\ToyOnly_2_25_25_S1P_Dallas_trimmed.mp4 and data.\n",
      "Duration of video [s]: 96.74, recorded with 24.99 fps!\n",
      "Overall # of frames: 2417 with cropped frame dimensions: 360 288\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2417/2417 [00:58<00:00, 41.23it/s]\n",
      "INFO:matplotlib.animation:MovieWriter._run: running command: ffmpeg -f rawvideo -vcodec rawvideo -s 360x288 -pix_fmt rgba -framerate 24.990258602450503 -loglevel error -i pipe: -vcodec h264 -pix_fmt yuv420p -y 'C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_J_trimmedDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_filtered_p30_labeled.mp4'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled video C:\\DeepLabCutProjects\\data\\Test\\ToyOnly_2_25_25_S1P_Dallas_trimmedDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_filtered_p30_labeled.mp4 successfully created.\n",
      "Starting to process video: C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_J_trimmed.mp4\n",
      "Loading C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_J_trimmed.mp4 and data.\n",
      "Duration of video [s]: 95.64, recorded with 24.99 fps!\n",
      "Overall # of frames: 2390 with cropped frame dimensions: 360 288\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2389/2389 [00:56<00:00, 42.08it/s]\n",
      "INFO:matplotlib.animation:MovieWriter._run: running command: ffmpeg -f rawvideo -vcodec rawvideo -s 360x288 -pix_fmt rgba -framerate 24.98774667654739 -loglevel error -i pipe: -vcodec h264 -pix_fmt yuv420p -y 'C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_K_trimmedDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_filtered_p30_labeled.mp4'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled video C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_J_trimmedDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_filtered_p30_labeled.mp4 successfully created.\n",
      "Starting to process video: C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_K_trimmed.mp4\n",
      "Loading C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_K_trimmed.mp4 and data.\n",
      "Duration of video [s]: 93.41, recorded with 24.99 fps!\n",
      "Overall # of frames: 2334 with cropped frame dimensions: 360 288\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2334/2334 [00:55<00:00, 42.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled video C:\\DeepLabCutProjects\\data\\Test\\ToyOnlyInhibitory_2_27_25_S3P_K_trimmedDLC_Resnet50_DLC-WhiteAnimalsJul23shuffle3_snapshot_100_filtered_p30_labeled.mp4 successfully created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True, True, True]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# video_dir = r\"C:\\DeepLabCutProjects\\data\\FoodOnly\\SplitVideos\"\n",
    "# videolist = [os.path.join(video_dir, f) for f in os.listdir(video_dir) if f.endswith(('.mp4', '.avi'))]\n",
    "\n",
    "# videolist = [r\"C:\\DeepLabCutProjects\\DLC-Atanu-2025-06-10\\videos\\FoodOnly\\FoodOnly_8_28_24_S3P_Cyan_Trial1.mp4\"]\n",
    "\n",
    "# deeplabcut.create_labeled_video(config_path, videolist, draw_skeleton=False, filtered=True)\n",
    "\n",
    "deeplabcut.create_labeled_video(\n",
    "    config_path,\n",
    "    videolist,\n",
    "    shuffle=3,\n",
    "    filtered=True,\n",
    "    fastmode=False,\n",
    "    save_frames=False,\n",
    "    displayedbodyparts=['Head', 'Neck', 'Midback', 'Lowerback', 'Tailbase']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "deeplabcut.plot_trajectories(config_path, videolist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Active Learning -> Network Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load new videos to analyze and/or merge to the project:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract outlier frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is the interesting part. Instead of including more videos to the project directly, and extracting frames as usual with kmeans, we are taking advantage of the previous model to tell us what frames exactly to label. This active learning step helps us recognize the shortcomings of our model and correct it in a targeted manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames(config_path, videolist, outlieralgorithm='uncertain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refine Labels: Augmentation of the Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have extracted new frames, we need to go back and start labeling. Instead of starting from the beginning, though, we are provided the model predictions and have to drag and drop them in place. **Note:** Make sure to remove labels that are not visible, the model will often guess the expected position based on learned geometric constraints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.refine_labels(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can again plot your labeled frames to check annotation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you could get an error message like [this](https://github.com/DeepLabCut/DeepLabCut/issues/232) telling you that saving the video path failed. In this case, you need to add the new video paths manually for DLC to include these in the new training set. You can either add them by hand, writing in the config.yaml file in the same format as the first video paths (see [here](https://github.com/DeepLabCut/DeepLabCut/issues/663#issuecomment-619274975)), or you can run the following command to add the list of videos to your config file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the permission error persists, try starting a new anaconda terminal as administrator (right click > run as administrator) and then starting jupyter notebook with elevated privileges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After refining all outlier frames extracted above, merge the datasets to combine old and new labels in your project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.merge_datasets(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Make sure that the new videos have been included in the config.yaml file without permission issues (see above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Train Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training a new model with an expanded dataset, you could either choose to start fresh with new data, or use the previous model as pre-trained network for your next model. Although not yet extensively verified, lets belief that transfer learning at least won't harm the new model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of own pre-trained model\n",
    "init_weights: D:\\FacialExpression\\old-DLC-Project\\dlc-models\\iteration-0\\DLCApr14-trainset95shuffle1\\train\\snapshot-1030000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start over again..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9cf59f4f35cbd5b03b7320385623601e0d1d6065449752291df1bcf50543fed6"
  },
  "kernelspec": {
   "display_name": "Python (DEEPLABCUT)",
   "language": "python",
   "name": "deeplabcut"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
